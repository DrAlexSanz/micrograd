{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrAlexSanz/micrograd/blob/main/02_Makemore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n09nqI5a7dFg"
      },
      "source": [
        "# Goal of this notebook\n",
        "\n",
        "* Following Karpathy's 3rd lecture on Makemore\n",
        "\n",
        "https://youtu.be/TCH_1BHY58I?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&t=2279"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # for later\n",
        "import torch.nn.functional as F # for later\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "QJrqMJYYuT2o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "id": "BlP41EL2o1rr",
        "outputId": "ecf05fd0-3078-4f79-d20c-8fe163b5553c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-14 13:45:05--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-12-14 13:45:05 (8.30 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(\"names.txt\", \"r\").read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "id": "oNwydlldkfWG",
        "outputId": "0677fa1e-15c9-4d21-a6d1-6027d8991078",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "id": "liNfE2d7kpD2",
        "outputId": "790ad536-a6cf-4181-c9e8-b846d350bee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "id": "87WP5bPyl7oO",
        "outputId": "acf961e2-cb5f-43ca-d23d-310ea74ea6fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the dataset for the NN\n",
        "\n",
        "block_size = 3 # This is the context lenght. How many characters do I take to predict the next one.\n",
        "\n",
        "X, Y = [], []\n",
        "\n",
        "for w in words[:5]:\n",
        "    print(w)\n",
        "    context = [0] * block_size\n",
        "\n",
        "    for ch in w + \".\":\n",
        "        ix = stoi[ch]\n",
        "        X.append(context)\n",
        "        Y.append(ix)\n",
        "        print(\"\".join(itos[i] for i in context), \"----->\", itos[ix])\n",
        "        context = context[1:] + [ix] # Crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "id": "byE1Kkwxk4x-",
        "outputId": "30ea4c85-5283-4e63-ea2d-8ebd86ad918b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... -----> e\n",
            "..e -----> m\n",
            ".em -----> m\n",
            "emm -----> a\n",
            "mma -----> .\n",
            "olivia\n",
            "... -----> o\n",
            "..o -----> l\n",
            ".ol -----> i\n",
            "oli -----> v\n",
            "liv -----> i\n",
            "ivi -----> a\n",
            "via -----> .\n",
            "ava\n",
            "... -----> a\n",
            "..a -----> v\n",
            ".av -----> a\n",
            "ava -----> .\n",
            "isabella\n",
            "... -----> i\n",
            "..i -----> s\n",
            ".is -----> a\n",
            "isa -----> b\n",
            "sab -----> e\n",
            "abe -----> l\n",
            "bel -----> l\n",
            "ell -----> a\n",
            "lla -----> .\n",
            "sophia\n",
            "... -----> s\n",
            "..s -----> o\n",
            ".so -----> p\n",
            "sop -----> h\n",
            "oph -----> i\n",
            "phi -----> a\n",
            "hia -----> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# And to see the shapes of what I will input in the NN (X) and the labels (Y)\n",
        "\n",
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ],
      "metadata": {
        "id": "jRYnFEazmo-O",
        "outputId": "85b0093f-0fc3-4edd-9f77-c0b14bf58d9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now I build the embedding layer (Remember it's a matrix multiplication in the end, that acts as a lookup table).\n",
        "# This is a neural network layer with no non-linearities.\n",
        "# I have 27 characters (rows) and I will embed them in a 2D vector space (columns). 2 is arbitrary\n",
        "\n",
        "# Initialize randomly\n",
        "C = torch.randn((27, 2))\n",
        "C"
      ],
      "metadata": {
        "id": "wm2fYlLEmydu",
        "outputId": "1c0170a7-fd56-4b97-f41a-cc4464221ee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.2721,  1.4637],\n",
              "        [ 0.4382,  0.1532],\n",
              "        [-0.8177, -1.2940],\n",
              "        [-0.8050,  0.6404],\n",
              "        [-1.2150,  0.4946],\n",
              "        [-1.6286, -0.8722],\n",
              "        [-0.6927,  0.5824],\n",
              "        [-0.1338, -0.8566],\n",
              "        [ 0.9942, -0.1670],\n",
              "        [ 2.9981,  0.8421],\n",
              "        [-0.4551,  0.0597],\n",
              "        [ 0.7267, -0.4338],\n",
              "        [ 0.3857, -1.7375],\n",
              "        [ 0.3362, -0.1526],\n",
              "        [-0.0389,  0.7885],\n",
              "        [ 0.2621, -0.9237],\n",
              "        [ 0.6052, -1.3118],\n",
              "        [ 1.2345, -0.3739],\n",
              "        [ 0.2678, -0.2567],\n",
              "        [ 0.1939,  0.7376],\n",
              "        [ 1.2741, -0.9261],\n",
              "        [ 0.6714, -0.3176],\n",
              "        [ 0.0067,  1.6626],\n",
              "        [ 1.1944,  0.7488],\n",
              "        [ 0.8947, -0.3699],\n",
              "        [-0.0654,  1.1566],\n",
              "        [-0.9388,  0.0951]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To embed the characters in this space (transform, no training yet) I can just index or matrix multiply them\n",
        "\n",
        "emb = C[X]\n",
        "print(emb.shape)\n",
        "# This will give me the 4th row of the C tensor\n",
        "print(C[X][3, 2])\n",
        "print(X[3, 2])\n",
        "print(C[13])"
      ],
      "metadata": {
        "id": "3kowCAedoaNX",
        "outputId": "2b1cf6da-3991-4258-d30d-2e4429e92d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 2])\n",
            "tensor([ 0.3362, -0.1526])\n",
            "tensor(13)\n",
            "tensor([ 0.3362, -0.1526])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we do the linear layer\n",
        "\n",
        "W1 = torch.randn(6, 100) # Weights 3 by 2 inputs, 100 neurons\n",
        "b1 = torch.randn(100)"
      ],
      "metadata": {
        "id": "x6jKOkS3pli3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# However, I can't multiply these matrices just like that. I need first to concatenate the 3D tensor along the second dimension\n",
        "\n",
        "# What I want is this, but it doesn't scale with the dimension\n",
        "# torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], dim = 1) #Shape should be 32x6\n",
        "\n",
        "concat = torch.cat((torch.unbind(emb, 1)), dim = 1) # Unbind produces a list as I was doing manually in the previous line. Then I concatenate them and the shape is the same.\n",
        "# However this is very inefficient. It's copying and creating new object in memeory"
      ],
      "metadata": {
        "id": "FmWDdjewqgAR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additionally, there is a better way to do this in this case.\n",
        "\n",
        "# I can just use view, which is very efficient\n",
        "\n",
        "concat_view = emb.view(32, 6) # (32, 3*2) And you can check that the results are the same"
      ],
      "metadata": {
        "id": "G39FNlkSrgV4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concat_view == concat # It's always True"
      ],
      "metadata": {
        "id": "64XpGCf1sdRR",
        "outputId": "6d734fef-5c5c-4ef4-8b2c-1914fd0e0ec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So then I calculate the hidden states that I want to pass to the tanh\n",
        "\n",
        "h = torch.tanh(emb.view(emb.shape[0], 6) @ W1 + b1) # And this will be 32 x 100"
      ],
      "metadata": {
        "id": "DrTLPpr5sm-Q"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and the softmax layer\n",
        "\n",
        "W2 = torch.randn((100, 27))\n",
        "b2 = torch.randn(27)"
      ],
      "metadata": {
        "id": "oenUEuZqs0ro"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = h @ W2 + b2"
      ],
      "metadata": {
        "id": "ZtKK2avCtubC"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()\n",
        "prob = counts / counts.sum(1, keepdims = True)"
      ],
      "metadata": {
        "id": "0VYObkyIt2A5"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So now for each row of the output, I take the probabilities by indexing\n",
        "\n",
        "loss = -prob[torch.arange(32), Y].log().mean()\n",
        "loss"
      ],
      "metadata": {
        "id": "p4Iqp-djuUep",
        "outputId": "09b20e8e-259b-4489-c775-7b10e6bd8b5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(20.5057)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's make this presentable for recap"
      ],
      "metadata": {
        "id": "Yf7hac8AwC8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # For reproducibility\n",
        "C = torch.randn((27, 2), generator = g)\n",
        "W1 = torch.randn((6, 100), generator = g)\n",
        "b1 = torch.randn((100), generator = g)\n",
        "W2 = torch.randn((100, 27), generator = g)\n",
        "b2 = torch.randn(27, generator = g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "pxfhSQu-wFPa"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # Count the number of parameters"
      ],
      "metadata": {
        "id": "pCJtvmxxwX3a",
        "outputId": "5f118c47-6eb4-4646-eedc-51b67b2e5064",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "dbt_13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c95f06af5cc293931129b1f6560e12509c2c49fa9f3d6bb87d157ed2f6fb8694"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}