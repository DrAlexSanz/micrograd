{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrAlexSanz/micrograd/blob/main/02_Makemore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n09nqI5a7dFg"
      },
      "source": [
        "# Goal of this notebook\n",
        "\n",
        "* Following Karpathy's 3rd lecture on Makemore\n",
        "\n",
        "https://youtu.be/TCH_1BHY58I?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&t=2279"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # for later\n",
        "import torch.nn.functional as F # for laterhttps://youtu.be/TCH_1BHY58I?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&t=2279\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "QJrqMJYYuT2o"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "id": "BlP41EL2o1rr",
        "outputId": "5819626c-21d1-48ec-dff8-b1397a17b0ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-05 10:44:59--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt.6’\n",
            "\n",
            "\rnames.txt.6           0%[                    ]       0  --.-KB/s               \rnames.txt.6         100%[===================>] 222.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-01-05 10:44:59 (11.3 MB/s) - ‘names.txt.6’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(\"names.txt\", \"r\").read().splitlines()\n",
        "#words[:8]"
      ],
      "metadata": {
        "id": "oNwydlldkfWG"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "id": "liNfE2d7kpD2",
        "outputId": "1325b3e9-88c2-4625-e653-8d9d7aed44d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "id": "87WP5bPyl7oO",
        "outputId": "6d77ce58-1301-4428-9c58-b1f3b27d24ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the dataset for the NN\n",
        "\n",
        "block_size = 3 # This is the context lenght. How many characters do I take to predict the next one.\n",
        "\n",
        "X, Y = [], []\n",
        "\n",
        "for w in words:\n",
        "    #print(w)\n",
        "    context = [0] * block_size\n",
        "\n",
        "    for ch in w + \".\":\n",
        "        ix = stoi[ch]\n",
        "        X.append(context)\n",
        "        Y.append(ix)\n",
        "        #print(\"\".join(itos[i] for i in context), \"----->\", itos[ix])\n",
        "        context = context[1:] + [ix] # Crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "id": "byE1Kkwxk4x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And to see the shapes of what I will input in the NN (X) and the labels (Y)\n",
        "\n",
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ],
      "metadata": {
        "id": "jRYnFEazmo-O",
        "outputId": "6099ca53-b0fa-4aa2-dc87-583ee34acbfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([228146, 3]), torch.int64, torch.Size([228146]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now I build the embedding layer (Remember it's a matrix multiplication in the end, that acts as a lookup table).\n",
        "# This is a neural network layer with no non-linearities.\n",
        "# I have 27 characters (rows) and I will embed them in a 2D vector space (columns). 2 is arbitrary\n",
        "\n",
        "# Initialize randomly\n",
        "C = torch.randn((27, 2))\n",
        "C"
      ],
      "metadata": {
        "id": "wm2fYlLEmydu",
        "outputId": "470cc9b1-891b-4cdc-c553-065527d95c8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4879,  0.6253],\n",
              "        [ 0.2169, -1.0615],\n",
              "        [-0.7011, -0.5842],\n",
              "        [ 0.2227,  1.0159],\n",
              "        [ 0.1758, -1.7483],\n",
              "        [ 0.7596,  0.3377],\n",
              "        [-0.8905, -0.4763],\n",
              "        [-0.1649,  0.9313],\n",
              "        [ 0.0654,  0.2417],\n",
              "        [ 0.1689,  0.0327],\n",
              "        [-2.0943,  1.4789],\n",
              "        [-0.8040, -0.6336],\n",
              "        [ 0.0190, -0.6924],\n",
              "        [-2.3341,  0.8161],\n",
              "        [-0.5792,  0.8404],\n",
              "        [-0.8375,  0.4751],\n",
              "        [-0.7118, -1.9520],\n",
              "        [ 0.8602,  0.6499],\n",
              "        [-1.7072,  0.8506],\n",
              "        [ 1.5254,  0.9495],\n",
              "        [-1.8308, -0.2287],\n",
              "        [ 0.3776,  0.9663],\n",
              "        [-0.1177,  0.4388],\n",
              "        [-0.0327,  1.2796],\n",
              "        [-0.9155,  1.3253],\n",
              "        [ 0.4963, -0.7943],\n",
              "        [-0.1347, -0.8412]])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To embed the characters in this space (transform, no training yet) I can just index or matrix multiply them\n",
        "\n",
        "emb = C[X]\n",
        "print(emb.shape)\n",
        "# This will give me the 4th row of the C tensor\n",
        "print(C[X][3, 2])\n",
        "print(X[3, 2])\n",
        "print(C[13])"
      ],
      "metadata": {
        "id": "3kowCAedoaNX",
        "outputId": "f886ca2b-c101-46aa-848e-c47b73f84c32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([228146, 3, 2])\n",
            "tensor([-2.3341,  0.8161])\n",
            "tensor(13)\n",
            "tensor([-2.3341,  0.8161])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we do the linear layer\n",
        "\n",
        "W1 = torch.randn(6, 100) # Weights 3 by 2 inputs, 100 neurons\n",
        "b1 = torch.randn(100)"
      ],
      "metadata": {
        "id": "x6jKOkS3pli3"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# However, I can't multiply these matrices just like that. I need first to concatenate the 3D tensor along the second dimension\n",
        "\n",
        "# What I want is this, but it doesn't scale with the dimension\n",
        "# torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], dim = 1) #Shape should be 32x6\n",
        "\n",
        "concat = torch.cat((torch.unbind(emb, 1)), dim = 1) # Unbind produces a list as I was doing manually in the previous line. Then I concatenate them and the shape is the same.\n",
        "# However this is very inefficient. It's copying and creating new object in memeory"
      ],
      "metadata": {
        "id": "FmWDdjewqgAR"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additionally, there is a better way to do this in this case.\n",
        "\n",
        "# I can just use view, which is very efficient\n",
        "\n",
        "#concat_view = emb.view(32, 6) # (32, 3*2) And you can check that the results are the same"
      ],
      "metadata": {
        "id": "G39FNlkSrgV4",
        "outputId": "4b07af72-9968-488b-8b75-842c0532c8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[32, 6]' is invalid for input of size 1368876",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-162-527efd37b9c7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# I can just use view, which is very efficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mconcat_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (32, 3*2) And you can check that the results are the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[32, 6]' is invalid for input of size 1368876"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concat_view == concat # It's always True"
      ],
      "metadata": {
        "id": "64XpGCf1sdRR"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So then I calculate the hidden states that I want to pass to the tanh\n",
        "\n",
        "h = torch.tanh(emb.view(emb.shape[0], 6) @ W1 + b1) # And this will be 32 x 100"
      ],
      "metadata": {
        "id": "DrTLPpr5sm-Q"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and the softmax layer\n",
        "\n",
        "W2 = torch.randn((100, 27))\n",
        "b2 = torch.randn(27)"
      ],
      "metadata": {
        "id": "oenUEuZqs0ro"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = h @ W2 + b2"
      ],
      "metadata": {
        "id": "ZtKK2avCtubC"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()\n",
        "prob = counts / counts.sum(1, keepdims = True)"
      ],
      "metadata": {
        "id": "0VYObkyIt2A5"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So now for each row of the output, I take the probabilities by indexing\n",
        "\n",
        "loss = -prob[torch.arange(228146), Y].log().mean()\n",
        "loss"
      ],
      "metadata": {
        "id": "p4Iqp-djuUep",
        "outputId": "183ec222-91d2-494e-aed1-6e6e733a1e47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14.7433)"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's make this presentable for recap"
      ],
      "metadata": {
        "id": "Yf7hac8AwC8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # For reproducibility\n",
        "C = torch.randn((27, 2), generator = g)\n",
        "W1 = torch.randn((6, 100), generator = g)\n",
        "b1 = torch.randn((100), generator = g)\n",
        "W2 = torch.randn((100, 27), generator = g)\n",
        "b2 = torch.randn(27, generator = g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "pxfhSQu-wFPa"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # Count the number of parameters"
      ],
      "metadata": {
        "id": "pCJtvmxxwX3a",
        "outputId": "deba9054-0946-4285-a403-98836c0cdadb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### So now, let's use pytorch's functions for optimizing on one batch.\n",
        "### Later, go up and comment the line where I take the first 5 words of the dataset"
      ],
      "metadata": {
        "id": "sjv8yEqZG-nJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass\n",
        "# emb = C[X] # shape is (32, 2, 2)\n",
        "# h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # Shape is (32, 100)\n",
        "# logits = h @ W2 + 2 # Shape is (32, 37)\n",
        "# counts = logits.exp()\n",
        "# prob = counts / counts.sum(1, keepdims = True)\n",
        "# loss = -prob[torch.arange(32), Y].log().mean()\n",
        "# loss = F.cross_entropy(logits, Y)\n",
        "# loss"
      ],
      "metadata": {
        "id": "zWihHv4sG-T4"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure everything that is a parameters accepts gradients\n",
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "6719AHJlKFMp"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now I add the backward pass and put it in the loop, to optimize only on one batch. I should overfit quickly.\n",
        "\n",
        "for _ in range(10):\n",
        "    # Forward pass\n",
        "    emb = C[X] # shape is (32, 2, 2)\n",
        "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # Shape is (32, 100)\n",
        "    logits = h @ W2 + 2 # Shape is (32, 37)\n",
        "    loss = F.cross_entropy(logits, Y)\n",
        "    print(loss.item())\n",
        "\n",
        "    # Backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = torch.zeros(p.shape, dtype=torch.float32) # Set them to 0. Apparently python doesn't like None insetad of 0\n",
        "    loss.backward() # calculate gradients\n",
        "\n",
        "    # Gradient update stage\n",
        "    for p in parameters:\n",
        "        p.data += -0.1 * p.grad # lr is 0.1 here\n",
        "\n"
      ],
      "metadata": {
        "id": "_V_MqtEOH6P4",
        "outputId": "c1754f83-1806-4dca-f82f-1d22ea7aa474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.1424503326416\n",
            "16.641582489013672\n",
            "15.451205253601074\n",
            "14.499948501586914\n",
            "13.695572853088379\n",
            "12.988574981689453\n",
            "12.366576194763184\n",
            "11.82927417755127\n",
            "11.383988380432129\n",
            "11.017670631408691\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "dbt_13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c95f06af5cc293931129b1f6560e12509c2c49fa9f3d6bb87d157ed2f6fb8694"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}